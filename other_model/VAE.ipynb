{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(object):\n",
    "    #This is VAE model that you should implement\n",
    "    def __init__(self, hidden_units=128, z_units=20, input_dim=784, batch_size=64):\n",
    "        \"\"\"\n",
    "        initialize all parameters in the model.\n",
    "        Encoding part:\n",
    "        1. W_input_hidden, b_input_hidden: convert input to hidden\n",
    "        2. W_hidden_mu, b_hidden_mu:\n",
    "        3. W_hidden_logvar, b_hidden_logvar\n",
    "        Sampling:\n",
    "        1. random_sample\n",
    "        Decoding part:\n",
    "        1. W_z_hidden, b_z_hidden\n",
    "        2. W_hidden_out, b_hidden_out\n",
    "        \"\"\"\n",
    "        self.hidden_units = hidden_units\n",
    "        self.z_units = z_units\n",
    "        self.input_dim = input_dim\n",
    "        \n",
    "        self.W_input_hidden = np.random.randn(input_dim, hidden_units) * 0.01\n",
    "        self.b_input_hidden = np.zeros((hidden_units))\n",
    "        self.e_lrelu = LRelu('VAE')\n",
    "        \n",
    "        self.W_hidden_mu = np.random.randn(hidden_units, z_units) * 0.01\n",
    "        self.b_hidden_mu = np.zeros((z_units))\n",
    "        \n",
    "        self.W_hidden_logvar = np.random.randn(hidden_units, z_units) * 0.01\n",
    "        self.b_hidden_logvar = np.zeros((z_units))\n",
    "        \n",
    "        self.W_z_hidden = np.random.randn(z_units, hidden_units) * 0.01\n",
    "        self.b_z_hidden = np.zeros((hidden_units))\n",
    "        self.d_relu = Relu()\n",
    "        \n",
    "        self.W_hidden_out = np.random.randn(hidden_units, input_dim) * 0.01\n",
    "        self.b_hidden_out = np.zeros((input_dim))\n",
    "        self.d_sigmoid = Sigmoid()\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"\n",
    "        input: x is input image with size (batch, indim)\n",
    "        return: hidden_mu, hidden_logvar, both sizes should be (batch, z_units)\n",
    "        \"\"\"\n",
    "        self.x = x\n",
    "        encode_hidden = x.dot(self.W_input_hidden) + self.b_input_hidden\n",
    "        self.leaky_encode_hidden = self.e_lrelu(encode_hidden)\n",
    "        \n",
    "        self.hidden_mu = self.leaky_encode_hidden.dot(self.W_hidden_mu) + self.b_hidden_mu\n",
    "        self.hidden_logvar = self.leaky_encode_hidden.dot(self.W_hidden_logvar) + self.b_hidden_logvar\n",
    "        \n",
    "        return self.hidden_mu, self.hidden_logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        \"\"\"\n",
    "        input: z is the result from sampling with size (batch, z_unit)\n",
    "        return: out, the generated images from decoder with size (batch, indim)\n",
    "        \"\"\"\n",
    "        decode_hidden = z.dot(self.W_z_hidden) + self.b_z_hidden\n",
    "        self.relu_decode_hidden = self.d_relu(decode_hidden)\n",
    "        leaky_decode_out = self.relu_decode_hidden.dot(self.W_hidden_out) + self.b_hidden_out\n",
    "        decode_out = self.d_sigmoid(leaky_decode_out)\n",
    "        return decode_out\n",
    "\n",
    "    def forward(self, x, unittest=False):\n",
    "        \"\"\"\n",
    "        combining encode, sampling and decode.\n",
    "        input: x is input image with size (batch, indim)\n",
    "        return: out, the generated images from decoder with size (batch, indim)\n",
    "        \"\"\"\n",
    "        if (unittest): np.random.seed(1433125)\n",
    "        self.hidden_mu, self.hidden_logvar = self.encode(x)\n",
    "        self.epsilon = np.random.randn(x.shape[0], self.z_units)\n",
    "        self.z = self.hidden_mu + self.epsilon * np.sqrt(np.exp(self.hidden_logvar))\n",
    "        out = self.decode(self.z)\n",
    "        return out\n",
    "    \n",
    "    def loss(self, x, out):\n",
    "        \"\"\"\n",
    "        Given the input x (also the ground truth) and out, computing the loss (CrossEntropy + KL).\n",
    "        input: x is the input of the model with size (batch, indim)\n",
    "               out is the predicted output of the model with size (batch, indim)\n",
    "        IMPORTANT: the loss computed should be divided by batch size.\n",
    "        \"\"\"\n",
    "        loss = (BCE_loss(out, x) - \n",
    "                0.5 * np.sum((1 + self.hidden_logvar - self.hidden_mu **2 - np.exp(self.hidden_logvar)))) / x.shape[0]\n",
    "        return loss\n",
    "        \n",
    "    def backward(self, x, pred):\n",
    "        \"\"\"\n",
    "        Given the input x (also the ground truth) and out, computing the gradient of parameters.\n",
    "        input: x is the input of the model with size (batch, indim)\n",
    "               pred is the predicted output of the model with size (batch, indim)\n",
    "        return: grad_list = [dW_input_hidden, db_input_hidden, dW_hidden_mu, db_hidden_mu, dW_hidden_logvar, \n",
    "        db_hidden_logvar,\n",
    "                            dW_z_hidden, db_z_hidden, dW_hidden_out, db_hidden_out]\n",
    "        IMPORTANT: make sure the gradients follows the exact same order in grad_list.\n",
    "        \"\"\"\n",
    "        batch = pred.shape[0]\n",
    "        \n",
    "        d_pred = - x / pred + (1 - x) / (1 - pred)\n",
    "        db_hidden_out = self.d_sigmoid.backward(d_pred)\n",
    "        dW_hidden_out = self.relu_decode_hidden.T.dot(db_hidden_out)#  / batch\n",
    "        db_z_hidden = self.d_relu.backward(db_hidden_out.dot(self.W_hidden_out.T))\n",
    "        dW_z_hidden = self.z.T.dot(db_z_hidden)\n",
    "        \n",
    "        dz = db_z_hidden.dot(self.W_z_hidden.T)\n",
    "        dmu = dz + self.hidden_mu\n",
    "        dlogvar = dz * (0.5 * np.exp(0.5 * self.hidden_logvar)*self.epsilon) + 0.5 * (np.exp(self.hidden_logvar) - 1)\n",
    "        \n",
    "        db_hidden_logvar = dlogvar\n",
    "        dW_hidden_logvar = self.leaky_encode_hidden.T.dot(dlogvar)\n",
    "        db_hidden_mu = dmu\n",
    "        dW_hidden_mu = self.leaky_encode_hidden.T.dot(dmu)\n",
    "        \n",
    "        db_input_hidden = self.e_lrelu.backward(db_hidden_mu.dot(self.W_hidden_mu.T) + db_hidden_logvar.dot(self.W_hidden_logvar.T))\n",
    "        dW_input_hidden =  self.x.T.dot(db_input_hidden) \n",
    "\n",
    "        return [dW_input_hidden, \n",
    "                db_input_hidden.sum(0), \n",
    "                dW_hidden_mu, \n",
    "                db_hidden_mu.sum(0), \n",
    "                dW_hidden_logvar, \n",
    "                db_hidden_logvar.sum(0), \n",
    "                dW_z_hidden, \n",
    "                db_z_hidden.sum(0), \n",
    "                dW_hidden_out, \n",
    "                db_hidden_out.sum(0)]\n",
    "\n",
    "    def set_params(self, parameter_list):\n",
    "        \"\"\"\n",
    "        IMPORTANT: used by autograder and unit-test\n",
    "        TO set parameters with parameter_list\n",
    "        input: parameter_list = [W_input_hidden, b_input_hidden, W_hidden_mu, b_hidden_mu, W_hidden_logvar, \n",
    "        b_hidden_logvar,\n",
    "                            W_z_hidden, b_z_hidden, W_hidden_out, b_hidden_out]\n",
    "        \"\"\"\n",
    "        self.W_input_hidden = parameter_list[0]\n",
    "        self.b_input_hidden = parameter_list[1]\n",
    "        self.W_hidden_mu = parameter_list[2]\n",
    "        self.b_hidden_mu = parameter_list[3]\n",
    "        self.W_hidden_logvar = parameter_list[4]\n",
    "        self.b_hidden_logvar = parameter_list[5]\n",
    "        self.W_z_hidden = parameter_list[6]\n",
    "        self.b_z_hidden = parameter_list[7]\n",
    "        self.W_hidden_out = parameter_list[8]\n",
    "        self.b_hidden_out = parameter_list[9]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
